{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3ca101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import nqDataLoader as nq #data loading library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "370d8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>updrs108</th>\n",
       "      <th>afTap</th>\n",
       "      <th>sTap</th>\n",
       "      <th>nqScore</th>\n",
       "      <th>typingSpeed</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>14.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.117543</td>\n",
       "      <td>189.372549</td>\n",
       "      <td>1402930351.011_001_014.csv</td>\n",
       "      <td>1403706430.011_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.25</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>1402932300.060_001_014.csv</td>\n",
       "      <td>1403708258.060_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>True</td>\n",
       "      <td>25.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.223411</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>1401117235.067_001_014.csv</td>\n",
       "      <td>1401978395.067_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>False</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1401114972.068_001_014.csv</td>\n",
       "      <td>1401980765.068_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>True</td>\n",
       "      <td>26.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.50</td>\n",
       "      <td>0.175751</td>\n",
       "      <td>39.614035</td>\n",
       "      <td>1404311419.070_001_014.csv</td>\n",
       "      <td>1404743687.070_003_014.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>170.00</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>109.800000</td>\n",
       "      <td>1463511198.1063_001_014.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>True</td>\n",
       "      <td>28.00</td>\n",
       "      <td>75.5</td>\n",
       "      <td>140.00</td>\n",
       "      <td>0.246866</td>\n",
       "      <td>105.333333</td>\n",
       "      <td>1458723488.1064_001_014.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>True</td>\n",
       "      <td>12.00</td>\n",
       "      <td>118.0</td>\n",
       "      <td>170.50</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>1460104760.1066_001_014.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>True</td>\n",
       "      <td>26.00</td>\n",
       "      <td>65.5</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.125523</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>1460559248.1068_001_014.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>False</td>\n",
       "      <td>2.00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>154.50</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>54.933333</td>\n",
       "      <td>1463130212.1070_001_014.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gt  updrs108  afTap    sTap   nqScore  typingSpeed  \\\n",
       "pID                                                           \n",
       "11     True     14.25    NaN  162.25  0.117543   189.372549   \n",
       "60    False      2.00    NaN  162.25  0.070350    60.533333   \n",
       "67     True     25.25    NaN  133.75  0.223411    54.333333   \n",
       "68    False      6.00    NaN  159.00  0.074973    71.800000   \n",
       "70     True     26.25    NaN  113.50  0.175751    39.614035   \n",
       "...     ...       ...    ...     ...       ...          ...   \n",
       "1063  False      0.00  110.0  170.00 -0.005529   109.800000   \n",
       "1064   True     28.00   75.5  140.00  0.246866   105.333333   \n",
       "1066   True     12.00  118.0  170.50  0.033189   140.250000   \n",
       "1068   True     26.00   65.5   98.00  0.125523    48.800000   \n",
       "1070  False      2.00  126.0  154.50  0.015485    54.933333   \n",
       "\n",
       "                           file_1                      file_2  \n",
       "pID                                                            \n",
       "11     1402930351.011_001_014.csv  1403706430.011_003_014.csv  \n",
       "60     1402932300.060_001_014.csv  1403708258.060_003_014.csv  \n",
       "67     1401117235.067_001_014.csv  1401978395.067_003_014.csv  \n",
       "68     1401114972.068_001_014.csv  1401980765.068_003_014.csv  \n",
       "70     1404311419.070_001_014.csv  1404743687.070_003_014.csv  \n",
       "...                           ...                         ...  \n",
       "1063  1463511198.1063_001_014.csv                         NaN  \n",
       "1064  1458723488.1064_001_014.csv                         NaN  \n",
       "1066  1460104760.1066_001_014.csv                         NaN  \n",
       "1068  1460559248.1068_001_014.csv                         NaN  \n",
       "1070  1463130212.1070_001_014.csv                         NaN  \n",
       "\n",
       "[85 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct file path with extension\n",
    "addedscores = pd.read_csv('data_composite/scores_composite.csv')\n",
    "\n",
    "# Set 'pID' as the index\n",
    "addedscores = addedscores.set_index('pID')\n",
    "\n",
    "# Display the first few rows\n",
    "addedscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the .csv files file_1 + file_2 par pID\n",
    "data_folder = os.path.join(\"data composite\", \"data source composite\")\n",
    "output_folder = \"concatenated_files\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for index, row in addedscores.iterrows():\n",
    "    file_1 = os.path.join(data_folder, row['file_1'])\n",
    "    file_2 = row['file_2']\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df1 = pd.read_csv(file_1)\n",
    "        # Apply strip only to string (object) columns\n",
    "        object_columns = df1.select_dtypes(['object']).columns\n",
    "        df1[object_columns] = df1[object_columns].apply(lambda x: x.str.strip())\n",
    "        \n",
    "        if pd.notna(file_2):\n",
    "            file_2 = os.path.join(data_folder, file_2)\n",
    "            df2 = pd.read_csv(file_2)\n",
    "            # Apply strip only to string (object) columns\n",
    "            object_columns = df2.select_dtypes(['object']).columns\n",
    "            df2[object_columns] = df2[object_columns].apply(lambda x: x.str.strip())\n",
    "            \n",
    "            # Concatenate dataframes\n",
    "            concatenated_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            concatenated_df = df1\n",
    "        \n",
    "        # Keep only the first four columns\n",
    "        concatenated_df = concatenated_df.iloc[:, :4]\n",
    "\n",
    "        # Save the concatenated DataFrame\n",
    "        concatenated_df.to_csv(os.path.join(output_folder, f\"{index}_combined.csv\"), index=False)\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error with pID {index}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and saved in the 'refined_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# In the combined.csv files, keep A to Z, 0 to 9 and space. Replace other entries by NaN\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the folders\n",
    "source_folder = \"concatenated_files\"\n",
    "output_folder = \"refined_data\"\n",
    "\n",
    "# Create the output_folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# List all the .csv files in the source folder\n",
    "csv_files = [file for file in os.listdir(source_folder) if file.endswith('.csv')]\n",
    "\n",
    "# Define a regular expression pattern that matches the allowed entries\n",
    "# This pattern looks for single characters a-z or digits 0-9, or the exact word 'space'\n",
    "allowed_pattern = re.compile(r'^[a-z0-9]$|^space$')\n",
    "\n",
    "# Function to replace unwanted entries with NaN\n",
    "def clean_entry(entry):\n",
    "    if pd.isna(entry):\n",
    "        return entry\n",
    "    str_entry = str(entry).strip().lower()  # Convert to lowercase to match the pattern\n",
    "    if allowed_pattern.fullmatch(str_entry):\n",
    "        return str_entry\n",
    "    else:\n",
    "        return \"NaN\"\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    input_file_path = os.path.join(source_folder, csv_file)\n",
    "\n",
    "    output_file_name = csv_file.replace('combined', 'refined')\n",
    "    output_file_path = os.path.join(output_folder, output_file_name)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Apply the function to clean the first column\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].apply(clean_entry)\n",
    "    \n",
    "    # Save the modified DataFrame to the new folder\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"All files have been processed and saved in the 'refined_data' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and saved in the 'refined2_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# remove lines before the first 'space'\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folders\n",
    "source_folder = \"refined_data\"  # The folder with the original refined data\n",
    "destination_folder = \"refined2_data\"  # The folder for the second round of refined data\n",
    "\n",
    "# Create the destination_folder if it does not exist\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# List all the .csv files in the source_folder\n",
    "csv_files = [file for file in os.listdir(source_folder) if file.endswith('.csv')]\n",
    "\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    input_file_path = os.path.join(source_folder, csv_file)\n",
    "    output_file_name = csv_file.replace('refined', 'refined2')\n",
    "    output_file_path = os.path.join(destination_folder, output_file_name)\n",
    "    \n",
    "    # Read the CSV file without headers\n",
    "    df = pd.read_csv(input_file_path, header=None)\n",
    "    \n",
    "    # Find the first occurrence of \"space\" in the first column\n",
    "    first_space_index = df[df.iloc[:, 0] == 'space'].index.min()\n",
    "    \n",
    "    # Remove all rows above the first \"space\" entry\n",
    "    df = df.loc[first_space_index:].reset_index(drop=True)\n",
    "    \n",
    "    # Save the modified DataFrame to the new folder\n",
    "    df.to_csv(output_file_path, index=False, header=False)\n",
    "\n",
    "print(\"All files have been processed and saved in the 'refined2_data' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
